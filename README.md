# ğŸš€ Trabalho de Compiladores

OlÃ¡! Este Ã© nosso **Trabalho de Compiladores** que realizamos no 7Âº semestre do Curso de CiÃªncias Da ComputaÃ§Ã£o para a matÃ©ria de Compiladores. ğŸ§ ğŸ’»

---

## ğŸ“š Sobre o Projeto

Este projeto tem como objetivo demonstrar, de forma prÃ¡tica, as etapas clÃ¡ssicas do funcionamento de um compilador. AtravÃ©s do desenvolvimento de um compilador simples, buscamos aplicar os conceitos teÃ³ricos estudados em sala de aula, como anÃ¡lise lÃ©xica, anÃ¡lise sintÃ¡tica, anÃ¡lise semÃ¢ntica, geraÃ§Ã£o de cÃ³digo e otimizaÃ§Ãµes bÃ¡sicas. O projeto proporciona uma compreensÃ£o mais profunda dos mecanismos internos de compilaÃ§Ã£o, reforÃ§ando o aprendizado e a importÃ¢ncia de cada etapa no processo de traduÃ§Ã£o de linguagens de alto nÃ­vel para cÃ³digo executÃ¡vel.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- Linguagem de ProgramaÃ§Ã£o: `Python` 
- Paradigma Utilizado: ProgramaÃ§Ã£o Orientada a Objetos (POO)
- Funcionalidades Implementadas Manualmente:
  - **Analisador LÃ©xico (Lexer):** desenvolvido do zero em Python, sem uso de ferramentas externas como Flex.
  - **Sistema de Tokens:** usando enum.Enum para definir os tipos de tokens da linguagem.
  - **Leitura Interativa de CÃ³digo:**  via input() para permitir que o usuÃ¡rio insira seu prÃ³prio cÃ³digo fonte em tempo real.

---

## ğŸ“‚ Estrutura do Projeto
- **lexer.py**: Arquivo que implementa o analisador lÃ©xico da linguagem. Ele Ã© responsÃ¡vel por percorrer o cÃ³digo-fonte, identificar os diferentes componentes (como palavras-chave, operadores, identificadores, literais, etc.) e gerar uma lista de tokens que representam esses elementos de forma estruturada. Inclui as definiÃ§Ãµes das classes TokenType, Token e Lexer.
- **main.py**: Este Ã© o ponto de entrada do programa. Ele permite ao usuÃ¡rio digitar ou colar um cÃ³digo-fonte personalizado para ser analisado. Internamente, ele instancia o Lexer, realiza a tokenizaÃ§Ã£o do cÃ³digo e imprime os tokens identificados. Serve como interface principal de uso do analisador.
 



